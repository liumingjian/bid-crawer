# æ‹›æ ‡ä¿¡æ¯çˆ¬è™«ç³»ç»Ÿ - å¼€å‘æ–‡æ¡£

## 1. ç³»ç»Ÿæ¶æ„

### 1.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ä¸»æ§åˆ¶å™¨ (main.py)                        â”‚
â”‚                    è´Ÿè´£è°ƒåº¦ã€æµç¨‹æ§åˆ¶ã€å¼‚å¸¸å¤„ç†                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é…ç½®ç®¡ç†å™¨    â”‚      â”‚   çˆ¬è™«å¼•æ“     â”‚      â”‚  æŠ¥å‘Šç”Ÿæˆå™¨    â”‚
â”‚ ConfigManager â”‚      â”‚ CrawlerEngine â”‚      â”‚ ReportGeneratorâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  config.yaml  â”‚      â”‚  ç½‘ç«™è§£æå™¨    â”‚      â”‚  HTMLæ¨¡æ¿     â”‚
â”‚               â”‚      â”‚   Parsers     â”‚      â”‚  templates/   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼               â–¼               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  CCGP     â”‚   â”‚  CEBP     â”‚   â”‚  å…¶ä»–...   â”‚
        â”‚  Parser   â”‚   â”‚  Parser   â”‚   â”‚  Parser   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 ç›®å½•ç»“æ„

```
bid-crawler/
â”œâ”€â”€ docs/                       # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ requirements.md         # éœ€æ±‚æ–‡æ¡£
â”‚   â””â”€â”€ development.md          # å¼€å‘æ–‡æ¡£
â”œâ”€â”€ src/                        # æºä»£ç ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # ä¸»å…¥å£
â”‚   â”œâ”€â”€ config/                 # é…ç½®æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config_manager.py   # é…ç½®ç®¡ç†å™¨
â”‚   â”‚   â””â”€â”€ settings.py         # é»˜è®¤è®¾ç½®
â”‚   â”œâ”€â”€ crawler/                # çˆ¬è™«æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ engine.py           # çˆ¬è™«å¼•æ“
â”‚   â”‚   â”œâ”€â”€ base_parser.py      # è§£æå™¨åŸºç±»
â”‚   â”‚   â””â”€â”€ parsers/            # å„ç½‘ç«™è§£æå™¨
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ ccgp_parser.py  # ä¸­å›½æ”¿åºœé‡‡è´­ç½‘
â”‚   â”‚       â”œâ”€â”€ cebp_parser.py  # ä¸­å›½æ‹›æ ‡æŠ•æ ‡å…¬å…±æœåŠ¡å¹³å°
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ filter/                 # æ•°æ®ç­›é€‰æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_filter.py      # æ•°æ®ç­›é€‰å™¨
â”‚   â”œâ”€â”€ report/                 # æŠ¥å‘Šç”Ÿæˆæ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ generator.py        # æŠ¥å‘Šç”Ÿæˆå™¨
â”‚   â”‚   â””â”€â”€ templates/          # HTMLæ¨¡æ¿
â”‚   â”‚       â””â”€â”€ report.html     # æŠ¥å‘Šæ¨¡æ¿
â”‚   â”œâ”€â”€ models/                 # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ bid_info.py         # æ‹›æ ‡ä¿¡æ¯æ¨¡å‹
â”‚   â””â”€â”€ utils/                  # å·¥å…·æ¨¡å—
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py           # æ—¥å¿—å·¥å…·
â”‚       â”œâ”€â”€ http_client.py      # HTTPå®¢æˆ·ç«¯
â”‚       â””â”€â”€ helpers.py          # è¾…åŠ©å‡½æ•°
â”œâ”€â”€ config/                     # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ config.yaml             # ä¸»é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ config.example.yaml     # é…ç½®ç¤ºä¾‹
â”œâ”€â”€ reports/                    # æŠ¥å‘Šè¾“å‡ºç›®å½•
â”œâ”€â”€ logs/                       # æ—¥å¿—ç›®å½•
â”œâ”€â”€ tests/                      # æµ‹è¯•ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_crawler.py
â”‚   â””â”€â”€ test_filter.py
â”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ setup.py                    # å®‰è£…è„šæœ¬
â”œâ”€â”€ run.sh                      # Linuxè¿è¡Œè„šæœ¬
â”œâ”€â”€ run.bat                     # Windowsè¿è¡Œè„šæœ¬
â””â”€â”€ README.md                   # é¡¹ç›®è¯´æ˜
```

## 2. æ¨¡å—è®¾è®¡

### 2.1 é…ç½®ç®¡ç†æ¨¡å— (config/)

#### 2.1.1 ConfigManager ç±»

```python
class ConfigManager:
    """é…ç½®ç®¡ç†å™¨
    
    è´Ÿè´£åŠ è½½ã€éªŒè¯ã€è®¿é—®é…ç½®ä¿¡æ¯
    """
    
    def __init__(self, config_path: str = "config/config.yaml"):
        """åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨"""
        pass
    
    def load(self) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        pass
    
    def validate(self) -> bool:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        pass
    
    def get_websites(self) -> List[WebsiteConfig]:
        """è·å–å¯ç”¨çš„ç½‘ç«™åˆ—è¡¨"""
        pass
    
    def get_keywords(self) -> List[str]:
        """è·å–æ‰€æœ‰å…³é”®è¯"""
        pass
    
    def get_industries(self) -> List[IndustryConfig]:
        """è·å–è¡Œä¸šé…ç½®"""
        pass
    
    def reload(self) -> None:
        """é‡æ–°åŠ è½½é…ç½®ï¼ˆæ”¯æŒçƒ­æ›´æ–°ï¼‰"""
        pass
```

#### 2.1.2 é…ç½®æ–‡ä»¶æ ¼å¼ (config.yaml)

```yaml
# ============================================
# æ‹›æ ‡ä¿¡æ¯çˆ¬è™«ç³»ç»Ÿé…ç½®æ–‡ä»¶
# ============================================

# çˆ¬è™«åŸºç¡€é…ç½®
crawler:
  request_delay: 2              # è¯·æ±‚é—´éš”(ç§’)ï¼Œé¿å…é¢‘ç¹è¯·æ±‚
  timeout: 30                   # è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
  retry_times: 3                # å¤±è´¥é‡è¯•æ¬¡æ•°
  retry_delay: 5                # é‡è¯•é—´éš”(ç§’)
  max_pages: 10                 # æ¯ä¸ªç½‘ç«™æœ€å¤§é‡‡é›†é¡µæ•°
  user_agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"

# æ•°æ®ç­›é€‰é…ç½®
filters:
  date_range: 7                 # é‡‡é›†æœ€è¿‘Nå¤©çš„æ•°æ®
  min_amount: 0                 # æœ€å°é¢„ç®—é‡‘é¢(ä¸‡å…ƒ)ï¼Œ0è¡¨ç¤ºä¸é™
  max_amount: 0                 # æœ€å¤§é¢„ç®—é‡‘é¢(ä¸‡å…ƒ)ï¼Œ0è¡¨ç¤ºä¸é™
  title_must_contain: []        # æ ‡é¢˜å¿…é¡»åŒ…å«çš„è¯ï¼ˆANDå…³ç³»ï¼‰
  title_any_contain: []         # æ ‡é¢˜åŒ…å«ä»»æ„è¯å³å¯ï¼ˆORå…³ç³»ï¼‰

# ç›®æ ‡è¡Œä¸šé…ç½®
industries:
  - name: "é‡‘è"
    enabled: true
    keywords:
      - "é“¶è¡Œ"
      - "è¯åˆ¸"
      - "ä¿é™©"
      - "åŸºé‡‘"
      - "ä¿¡æ‰˜"
      - "é‡‘è"
  
  - name: "åŒ»ç–—"
    enabled: true
    keywords:
      - "åŒ»é™¢"
      - "å«å¥å§”"
      - "å«ç”Ÿå¥åº·"
      - "ç–¾æ§ä¸­å¿ƒ"
      - "åŒ»ç–—"
      - "ä¸­åŒ»é™¢"
  
  - name: "è¿è¥å•†"
    enabled: true
    keywords:
      - "ç§»åŠ¨"
      - "è”é€š"
      - "ç”µä¿¡"
      - "å¹¿ç”µ"
      - "é€šä¿¡"
  
  - name: "æ”¿åºœ"
    enabled: true
    keywords:
      - "æ”¿åŠ¡"
      - "å¤§æ•°æ®å±€"
      - "æ•°æ®èµ„æº"
      - "æ”¿åºœ"
      - "æœºå…³"
  
  - name: "èƒ½æº"
    enabled: true
    keywords:
      - "ç”µåŠ›"
      - "ç”µç½‘"
      - "çŸ³æ²¹"
      - "çŸ³åŒ–"
      - "ç‡ƒæ°”"
      - "èƒ½æº"
  
  - name: "æ•™è‚²"
    enabled: true
    keywords:
      - "å¤§å­¦"
      - "å­¦é™¢"
      - "é«˜æ ¡"
      - "æ•™è‚²"

# æŠ€æœ¯å…³é”®è¯é…ç½®
tech_keywords:
  # è¿ç»´æœåŠ¡ç±»
  service:
    - "ç»´ä¿"
    - "è¿ç»´"
    - "æŠ€æœ¯æ”¯æŒ"
    - "é©»åœº"
    - "è¿è¥æœåŠ¡"
    - "æŠ€æœ¯æœåŠ¡"
  
  # æ•°æ®åº“ç±»
  database:
    - "æ•°æ®åº“"
    - "GaussDB"
    - "é«˜æ–¯æ•°æ®åº“"
    - "OceanBase"
    - "TiDB"
    - "è¾¾æ¢¦"
    - "äººå¤§é‡‘ä»“"
    - "MySQL"
    - "Oracle"
    - "PostgreSQL"
    - "SQL Server"
  
  # å¤§æ•°æ®ç±»
  bigdata:
    - "å¤§æ•°æ®"
    - "Hadoop"
    - "CDH"
    - "Cloudera"
    - "Spark"
    - "Hive"
    - "HBase"
    - "Kafka"
    - "Flink"
    - "ClickHouse"
    - "Doris"
    - "æ•°æ®ä»“åº“"
    - "æ•°æ®æ¹–"
    - "æ•°æ®ä¸­å°"
  
  # ä¸­é—´ä»¶ç±»
  middleware:
    - "ä¸­é—´ä»¶"
    - "Redis"
    - "RabbitMQ"
    - "Nginx"
    - "Tomcat"
    - "WebLogic"
    - "æ¶ˆæ¯é˜Ÿåˆ—"
    - "ç¼“å­˜"
  
  # ä¿¡åˆ›ç±»
  xinchuang:
    - "ä¿¡åˆ›"
    - "å›½äº§åŒ–"
    - "è‡ªä¸»å¯æ§"
    - "å›½äº§æ•°æ®åº“"
    - "å›½äº§ä¸­é—´ä»¶"

# ç›®æ ‡ç½‘ç«™é…ç½®
websites:
  - name: "ä¸­å›½æ”¿åºœé‡‡è´­ç½‘"
    url: "https://www.ccgp.gov.cn"
    search_url: "https://search.ccgp.gov.cn/bxsearch"
    enabled: true
    parser: "ccgp"
    encoding: "utf-8"
    notes: "æ”¿åºœé‡‡è´­ä¸»ç«™ï¼Œæ•°æ®é‡å¤§"
  
  - name: "ä¸­å›½æ‹›æ ‡æŠ•æ ‡å…¬å…±æœåŠ¡å¹³å°"
    url: "http://www.cebpubservice.com"
    search_url: "http://www.cebpubservice.com/xxgg/index.html"
    enabled: true
    parser: "cebp"
    encoding: "utf-8"
    notes: "ç»¼åˆæ‹›æ ‡å¹³å°"
  
  - name: "ä¸­å›½é‡‡è´­ä¸æ‹›æ ‡ç½‘"
    url: "https://www.chinabidding.cn"
    search_url: "https://www.chinabidding.cn/search/searchzbgg"
    enabled: true
    parser: "chinabidding"
    encoding: "utf-8"
    notes: "ç»¼åˆæ‹›æ ‡ä¿¡æ¯"
  
  - name: "å…¨å›½å…¬å…±èµ„æºäº¤æ˜“å¹³å°"
    url: "http://www.ggzy.gov.cn"
    search_url: "http://www.ggzy.gov.cn/information/html/a/index.html"
    enabled: false
    parser: "ggzy"
    encoding: "utf-8"
    notes: "å…¬å…±èµ„æºäº¤æ˜“ï¼Œç»“æ„å¤æ‚"
  
  - name: "æ¯”åœ°æ‹›æ ‡ç½‘"
    url: "https://www.bidizhaobiao.com"
    search_url: "https://www.bidizhaobiao.com/zbgg"
    enabled: false
    parser: "bidi"
    encoding: "utf-8"
    notes: "ç¬¬ä¸‰æ–¹æ‹›æ ‡èšåˆå¹³å°"

# è¾“å‡ºé…ç½®
output:
  report_dir: "./reports"                    # æŠ¥å‘Šè¾“å‡ºç›®å½•
  report_name: "bid_report_{date}.html"      # æŠ¥å‘Šæ–‡ä»¶åæ¨¡æ¿
  data_dir: "./data"                         # åŸå§‹æ•°æ®ä¿å­˜ç›®å½•
  save_raw_data: true                        # æ˜¯å¦ä¿å­˜åŸå§‹æ•°æ®(JSON)
  keep_days: 30                              # æŠ¥å‘Šä¿ç•™å¤©æ•°

# æ—¥å¿—é…ç½®
logging:
  level: "INFO"                              # æ—¥å¿—çº§åˆ«: DEBUG, INFO, WARNING, ERROR
  file: "./logs/crawler.log"                 # æ—¥å¿—æ–‡ä»¶è·¯å¾„
  max_size: 10                               # å•ä¸ªæ—¥å¿—æ–‡ä»¶æœ€å¤§MB
  backup_count: 5                            # ä¿ç•™æ—¥å¿—æ–‡ä»¶æ•°é‡
```

### 2.2 çˆ¬è™«å¼•æ“æ¨¡å— (crawler/)

#### 2.2.1 CrawlerEngine ç±»

```python
class CrawlerEngine:
    """çˆ¬è™«å¼•æ“
    
    è´Ÿè´£è°ƒåº¦å„ç½‘ç«™è§£æå™¨ï¼Œæ‰§è¡Œé‡‡é›†ä»»åŠ¡
    """
    
    def __init__(self, config: ConfigManager):
        """åˆå§‹åŒ–çˆ¬è™«å¼•æ“"""
        self.config = config
        self.parsers = {}
        self.http_client = HttpClient()
        self._register_parsers()
    
    def _register_parsers(self) -> None:
        """æ³¨å†Œæ‰€æœ‰å¯ç”¨çš„è§£æå™¨"""
        pass
    
    def crawl_all(self) -> List[BidInfo]:
        """é‡‡é›†æ‰€æœ‰å¯ç”¨ç½‘ç«™çš„æ•°æ®"""
        pass
    
    def crawl_website(self, website: WebsiteConfig) -> List[BidInfo]:
        """é‡‡é›†å•ä¸ªç½‘ç«™çš„æ•°æ®"""
        pass
    
    def get_parser(self, parser_name: str) -> BaseParser:
        """è·å–æŒ‡å®šè§£æå™¨"""
        pass
```

#### 2.2.2 BaseParser åŸºç±»

```python
from abc import ABC, abstractmethod

class BaseParser(ABC):
    """ç½‘ç«™è§£æå™¨åŸºç±»
    
    æ‰€æœ‰ç½‘ç«™è§£æå™¨å¿…é¡»ç»§æ‰¿æ­¤ç±»å¹¶å®ç°æŠ½è±¡æ–¹æ³•
    """
    
    def __init__(self, config: WebsiteConfig, http_client: HttpClient):
        self.config = config
        self.http_client = http_client
    
    @abstractmethod
    def get_list_url(self, page: int, keywords: List[str]) -> str:
        """æ„é€ åˆ—è¡¨é¡µURL"""
        pass
    
    @abstractmethod
    def parse_list(self, html: str) -> List[dict]:
        """è§£æåˆ—è¡¨é¡µï¼Œè¿”å›æ‹›æ ‡ä¿¡æ¯åŸºæœ¬æ•°æ®"""
        pass
    
    @abstractmethod
    def parse_detail(self, url: str) -> dict:
        """è§£æè¯¦æƒ…é¡µï¼Œè¿”å›å®Œæ•´æ‹›æ ‡ä¿¡æ¯"""
        pass
    
    def fetch_list(self, page: int, keywords: List[str]) -> List[BidInfo]:
        """è·å–åˆ—è¡¨é¡µæ•°æ®"""
        url = self.get_list_url(page, keywords)
        html = self.http_client.get(url)
        items = self.parse_list(html)
        return [BidInfo(**item) for item in items]
```

#### 2.2.3 è§£æå™¨å®ç°ç¤ºä¾‹ (CCGP)

```python
class CCGPParser(BaseParser):
    """ä¸­å›½æ”¿åºœé‡‡è´­ç½‘è§£æå™¨"""
    
    def get_list_url(self, page: int, keywords: List[str]) -> str:
        """æ„é€ æœç´¢URL
        
        ä¸­å›½æ”¿åºœé‡‡è´­ç½‘æœç´¢æ¥å£æ ¼å¼:
        https://search.ccgp.gov.cn/bxsearch?searchtype=1&page_index={page}&...
        """
        base_url = "https://search.ccgp.gov.cn/bxsearch"
        params = {
            "searchtype": "1",
            "page_index": page,
            "bidSort": "0",
            "pinMu": "0",
            "bidType": "1",  # 1=æ‹›æ ‡å…¬å‘Š
            "kw": "+".join(keywords)
        }
        return f"{base_url}?{urlencode(params)}"
    
    def parse_list(self, html: str) -> List[dict]:
        """è§£æåˆ—è¡¨é¡µ"""
        soup = BeautifulSoup(html, 'html.parser')
        results = []
        
        for item in soup.select('.vT-srch-result-list li'):
            title_elem = item.select_one('a')
            if not title_elem:
                continue
            
            results.append({
                'title': title_elem.get_text(strip=True),
                'url': title_elem.get('href'),
                'publish_date': self._extract_date(item),
                'purchaser': self._extract_purchaser(item),
                'source': 'ä¸­å›½æ”¿åºœé‡‡è´­ç½‘'
            })
        
        return results
    
    def parse_detail(self, url: str) -> dict:
        """è§£æè¯¦æƒ…é¡µ"""
        html = self.http_client.get(url)
        soup = BeautifulSoup(html, 'html.parser')
        
        # æå–è¯¦ç»†ä¿¡æ¯
        return {
            'bid_no': self._extract_bid_no(soup),
            'budget': self._extract_budget(soup),
            'deadline': self._extract_deadline(soup),
            'content': self._extract_content(soup)
        }
```

### 2.3 æ•°æ®æ¨¡å‹ (models/)

#### 2.3.1 BidInfo æ¨¡å‹

```python
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional, List

@dataclass
class BidInfo:
    """æ‹›æ ‡ä¿¡æ¯æ•°æ®æ¨¡å‹"""
    
    # åŸºæœ¬ä¿¡æ¯
    title: str                              # æ‹›æ ‡æ ‡é¢˜
    url: str                                # åŸæ–‡é“¾æ¥
    source: str                             # æ¥æºç½‘ç«™
    
    # æ‹›æ ‡è¯¦æƒ…
    bid_no: Optional[str] = None            # æ‹›æ ‡ç¼–å·
    purchaser: Optional[str] = None         # é‡‡è´­å•ä½
    agency: Optional[str] = None            # ä»£ç†æœºæ„
    publish_date: Optional[datetime] = None # å‘å¸ƒæ—¥æœŸ
    deadline: Optional[datetime] = None     # æˆªæ­¢æ—¥æœŸ
    budget: Optional[float] = None          # é¢„ç®—é‡‘é¢(ä¸‡å…ƒ)
    
    # åˆ†ç±»ä¿¡æ¯
    industry: Optional[str] = None          # æ‰€å±è¡Œä¸š
    matched_keywords: List[str] = field(default_factory=list)  # åŒ¹é…çš„å…³é”®è¯
    
    # å…ƒæ•°æ®
    crawl_time: datetime = field(default_factory=datetime.now) # é‡‡é›†æ—¶é—´
    content_hash: Optional[str] = None      # å†…å®¹å“ˆå¸Œ(ç”¨äºå»é‡)
    
    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        pass
    
    def match_keywords(self, keywords: List[str]) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ¹é…å…³é”®è¯"""
        pass
    
    def classify_industry(self, industries: List[IndustryConfig]) -> str:
        """è‡ªåŠ¨åˆ†ç±»è¡Œä¸š"""
        pass
```

### 2.4 æ•°æ®ç­›é€‰æ¨¡å— (filter/)

#### 2.4.1 DataFilter ç±»

```python
class DataFilter:
    """æ•°æ®ç­›é€‰å™¨
    
    è´Ÿè´£æ ¹æ®é…ç½®è§„åˆ™ç­›é€‰å’Œå»é‡æ‹›æ ‡ä¿¡æ¯
    """
    
    def __init__(self, config: ConfigManager):
        self.config = config
        self._seen_hashes = set()
    
    def filter(self, items: List[BidInfo]) -> List[BidInfo]:
        """æ‰§è¡Œç­›é€‰"""
        result = []
        for item in items:
            if self._should_include(item):
                result.append(item)
        return result
    
    def _should_include(self, item: BidInfo) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”åŒ…å«è¯¥é¡¹"""
        # å»é‡æ£€æŸ¥
        if not self._check_duplicate(item):
            return False
        
        # å…³é”®è¯æ£€æŸ¥
        if not self._match_keywords(item):
            return False
        
        # æ—¥æœŸæ£€æŸ¥
        if not self._check_date_range(item):
            return False
        
        # é‡‘é¢æ£€æŸ¥
        if not self._check_amount_range(item):
            return False
        
        return True
    
    def _check_duplicate(self, item: BidInfo) -> bool:
        """æ£€æŸ¥æ˜¯å¦é‡å¤"""
        hash_value = item.content_hash or hash(f"{item.title}{item.publish_date}")
        if hash_value in self._seen_hashes:
            return False
        self._seen_hashes.add(hash_value)
        return True
    
    def _match_keywords(self, item: BidInfo) -> bool:
        """æ£€æŸ¥å…³é”®è¯åŒ¹é…"""
        keywords = self.config.get_keywords()
        title_lower = item.title.lower()
        
        matched = []
        for kw in keywords:
            if kw.lower() in title_lower:
                matched.append(kw)
        
        item.matched_keywords = matched
        return len(matched) > 0
```

### 2.5 æŠ¥å‘Šç”Ÿæˆæ¨¡å— (report/)

#### 2.5.1 ReportGenerator ç±»

```python
class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨
    
    è´Ÿè´£ç”ŸæˆHTMLæ ¼å¼çš„æ‹›æ ‡ä¿¡æ¯æŠ¥å‘Š
    """
    
    def __init__(self, config: ConfigManager):
        self.config = config
        self.template_path = "src/report/templates/report.html"
    
    def generate(self, items: List[BidInfo], output_path: str = None) -> str:
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        # å‡†å¤‡æ•°æ®
        context = self._prepare_context(items)
        
        # æ¸²æŸ“æ¨¡æ¿
        html = self._render_template(context)
        
        # ä¿å­˜æ–‡ä»¶
        if output_path is None:
            output_path = self._get_default_path()
        
        self._save_report(html, output_path)
        return output_path
    
    def _prepare_context(self, items: List[BidInfo]) -> dict:
        """å‡†å¤‡æ¨¡æ¿ä¸Šä¸‹æ–‡æ•°æ®"""
        return {
            'generate_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_count': len(items),
            'by_industry': self._group_by_industry(items),
            'by_source': self._group_by_source(items),
            'items': [item.to_dict() for item in items]
        }
    
    def _group_by_industry(self, items: List[BidInfo]) -> dict:
        """æŒ‰è¡Œä¸šåˆ†ç»„"""
        groups = {}
        for item in items:
            industry = item.industry or 'å…¶ä»–'
            if industry not in groups:
                groups[industry] = []
            groups[industry].append(item)
        return groups
```

#### 2.5.2 HTMLæ¨¡æ¿è®¾è®¡

```html
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ‹›æ ‡ä¿¡æ¯æŠ¥å‘Š - {{ generate_time }}</title>
    <style>
        /* å“åº”å¼è®¾è®¡æ ·å¼ */
        * { box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 20px;
        }
        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin-bottom: 20px;
        }
        .stat-card {
            background: white;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .bid-card {
            background: white;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 15px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .bid-title {
            font-size: 16px;
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 10px;
        }
        .bid-title a {
            color: #3498db;
            text-decoration: none;
        }
        .bid-meta {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            font-size: 14px;
            color: #666;
        }
        .keyword-tag {
            background: #e74c3c;
            color: white;
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 12px;
        }
        .industry-tag {
            background: #3498db;
            color: white;
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 12px;
        }
        .filter-bar {
            background: white;
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
        }
        .filter-bar input {
            width: 100%;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        @media (max-width: 768px) {
            body { padding: 10px; }
            .header { padding: 20px; }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>æ‹›æ ‡ä¿¡æ¯æŠ¥å‘Š</h1>
        <p>ç”Ÿæˆæ—¶é—´: {{ generate_time }}</p>
    </div>
    
    <div class="stats">
        <div class="stat-card">
            <h3>{{ total_count }}</h3>
            <p>æ‹›æ ‡æ€»æ•°</p>
        </div>
        {% for source, items in by_source.items() %}
        <div class="stat-card">
            <h3>{{ items|length }}</h3>
            <p>{{ source }}</p>
        </div>
        {% endfor %}
    </div>
    
    <div class="filter-bar">
        <input type="text" id="searchInput" placeholder="æœç´¢æ‹›æ ‡æ ‡é¢˜æˆ–å•ä½..." onkeyup="filterItems()">
    </div>
    
    <div id="bidList">
        {% for item in items %}
        <div class="bid-card" data-title="{{ item.title }}" data-purchaser="{{ item.purchaser }}">
            <div class="bid-title">
                <a href="{{ item.url }}" target="_blank">{{ item.title }}</a>
            </div>
            <div class="bid-meta">
                <span>ğŸ“… {{ item.publish_date }}</span>
                <span>ğŸ¢ {{ item.purchaser }}</span>
                {% if item.budget %}
                <span>ğŸ’° {{ item.budget }}ä¸‡å…ƒ</span>
                {% endif %}
                <span class="industry-tag">{{ item.industry }}</span>
                {% for kw in item.matched_keywords %}
                <span class="keyword-tag">{{ kw }}</span>
                {% endfor %}
            </div>
        </div>
        {% endfor %}
    </div>
    
    <script>
        function filterItems() {
            const input = document.getElementById('searchInput').value.toLowerCase();
            const cards = document.querySelectorAll('.bid-card');
            cards.forEach(card => {
                const title = card.dataset.title.toLowerCase();
                const purchaser = card.dataset.purchaser.toLowerCase();
                if (title.includes(input) || purchaser.includes(input)) {
                    card.style.display = 'block';
                } else {
                    card.style.display = 'none';
                }
            });
        }
    </script>
</body>
</html>
```

### 2.6 å·¥å…·æ¨¡å— (utils/)

#### 2.6.1 HttpClient ç±»

```python
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

class HttpClient:
    """HTTPå®¢æˆ·ç«¯
    
    å°è£…requestsï¼Œæä¾›é‡è¯•ã€ä»£ç†ã€é™é€Ÿç­‰åŠŸèƒ½
    """
    
    def __init__(self, config: dict = None):
        self.session = requests.Session()
        self._setup_retry()
        self._setup_headers(config)
        self.delay = config.get('request_delay', 2) if config else 2
    
    def _setup_retry(self):
        """é…ç½®é‡è¯•ç­–ç•¥"""
        retry = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[500, 502, 503, 504]
        )
        adapter = HTTPAdapter(max_retries=retry)
        self.session.mount('http://', adapter)
        self.session.mount('https://', adapter)
    
    def get(self, url: str, params: dict = None, **kwargs) -> str:
        """å‘é€GETè¯·æ±‚"""
        time.sleep(self.delay)  # é™é€Ÿ
        response = self.session.get(url, params=params, **kwargs)
        response.raise_for_status()
        return response.text
    
    def post(self, url: str, data: dict = None, **kwargs) -> str:
        """å‘é€POSTè¯·æ±‚"""
        time.sleep(self.delay)
        response = self.session.post(url, data=data, **kwargs)
        response.raise_for_status()
        return response.text
```

#### 2.6.2 Logger é…ç½®

```python
import logging
from logging.handlers import RotatingFileHandler

def setup_logger(config: dict) -> logging.Logger:
    """é…ç½®æ—¥å¿—"""
    logger = logging.getLogger('bid_crawler')
    logger.setLevel(config.get('level', 'INFO'))
    
    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = RotatingFileHandler(
        config.get('file', 'logs/crawler.log'),
        maxBytes=config.get('max_size', 10) * 1024 * 1024,
        backupCount=config.get('backup_count', 5),
        encoding='utf-8'
    )
    file_handler.setFormatter(logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    ))
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s'
    ))
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger
```

## 3. æŠ€æœ¯é€‰å‹

### 3.1 æ ¸å¿ƒä¾èµ–

| åº“å | ç‰ˆæœ¬ | ç”¨é€” |
|------|------|------|
| requests | >=2.28.0 | HTTPè¯·æ±‚ |
| beautifulsoup4 | >=4.11.0 | HTMLè§£æ |
| lxml | >=4.9.0 | HTML/XMLè§£æåŠ é€Ÿ |
| PyYAML | >=6.0 | é…ç½®æ–‡ä»¶è§£æ |
| Jinja2 | >=3.1.0 | HTMLæ¨¡æ¿æ¸²æŸ“ |
| python-dateutil | >=2.8.0 | æ—¥æœŸå¤„ç† |
| fake-useragent | >=1.1.0 | User-Agentç”Ÿæˆ |

### 3.2 å¯é€‰ä¾èµ–

| åº“å | ç”¨é€” |
|------|------|
| selenium | å¤„ç†JavaScriptæ¸²æŸ“é¡µé¢ |
| playwright | ç°ä»£åŒ–æµè§ˆå™¨è‡ªåŠ¨åŒ– |
| schedule | å®šæ—¶ä»»åŠ¡ |
| pandas | æ•°æ®å¤„ç†å’Œå¯¼å‡ºExcel |

## 4. éƒ¨ç½²æ–¹æ¡ˆ

### 4.1 è™šæ‹Ÿç¯å¢ƒè®¾ç½®

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ (Linux/Mac)
source venv/bin/activate

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ (Windows)
venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 4.2 è¿è¡Œè„šæœ¬

**Linux/Mac (run.sh):**
```bash
#!/bin/bash
cd "$(dirname "$0")"
source venv/bin/activate
python -m src.main "$@"
```

**Windows (run.bat):**
```batch
@echo off
cd /d "%~dp0"
call venv\Scripts\activate
python -m src.main %*
```

### 4.3 å®šæ—¶ä»»åŠ¡é…ç½®

**Linux Crontab:**
```bash
# æ¯å¤©æ—©ä¸Š8ç‚¹æ‰§è¡Œ
0 8 * * * /path/to/bid-crawler/run.sh >> /path/to/bid-crawler/logs/cron.log 2>&1
```

**Windows è®¡åˆ’ä»»åŠ¡:**
ä½¿ç”¨ä»»åŠ¡è®¡åˆ’ç¨‹åºåˆ›å»ºåŸºæœ¬ä»»åŠ¡ï¼Œæ‰§è¡Œ run.bat

## 5. æ‰©å±•æŒ‡å—

### 5.1 æ–°å¢ç½‘ç«™è§£æå™¨

1. åœ¨ `src/crawler/parsers/` ä¸‹åˆ›å»ºæ–°æ–‡ä»¶ï¼Œå¦‚ `new_site_parser.py`
2. ç»§æ‰¿ `BaseParser` ç±»å¹¶å®ç°æŠ½è±¡æ–¹æ³•
3. åœ¨ `config.yaml` ä¸­æ·»åŠ ç½‘ç«™é…ç½®
4. åœ¨ `CrawlerEngine._register_parsers()` ä¸­æ³¨å†Œæ–°è§£æå™¨

```python
# src/crawler/parsers/new_site_parser.py
from ..base_parser import BaseParser

class NewSiteParser(BaseParser):
    """æ–°ç½‘ç«™è§£æå™¨"""
    
    def get_list_url(self, page: int, keywords: List[str]) -> str:
        # å®ç°URLæ„é€ é€»è¾‘
        pass
    
    def parse_list(self, html: str) -> List[dict]:
        # å®ç°åˆ—è¡¨é¡µè§£æé€»è¾‘
        pass
    
    def parse_detail(self, url: str) -> dict:
        # å®ç°è¯¦æƒ…é¡µè§£æé€»è¾‘
        pass
```

### 5.2 æ·»åŠ æ–°çš„å…³é”®è¯ç±»åˆ«

åœ¨ `config.yaml` çš„ `tech_keywords` ä¸‹æ·»åŠ æ–°ç±»åˆ«ï¼š

```yaml
tech_keywords:
  # æ–°ç±»åˆ«
  new_category:
    - "å…³é”®è¯1"
    - "å…³é”®è¯2"
```

### 5.3 è‡ªå®šä¹‰æŠ¥å‘Šæ¨¡æ¿

1. å¤åˆ¶ `src/report/templates/report.html` ä¸ºæ–°æ¨¡æ¿
2. ä¿®æ”¹æ¨¡æ¿å†…å®¹å’Œæ ·å¼
3. åœ¨é…ç½®ä¸­æŒ‡å®šä½¿ç”¨æ–°æ¨¡æ¿

## 6. æµ‹è¯•è®¡åˆ’

### 6.1 å•å…ƒæµ‹è¯•

- ConfigManager: é…ç½®åŠ è½½ã€éªŒè¯ã€çƒ­æ›´æ–°
- DataFilter: å…³é”®è¯åŒ¹é…ã€æ—¥æœŸç­›é€‰ã€å»é‡é€»è¾‘
- BidInfo: æ•°æ®è½¬æ¢ã€åˆ†ç±»é€»è¾‘
- å„Parser: URLæ„é€ ã€HTMLè§£æ

### 6.2 é›†æˆæµ‹è¯•

- å®Œæ•´é‡‡é›†æµç¨‹æµ‹è¯•
- æŠ¥å‘Šç”Ÿæˆæµ‹è¯•
- å®šæ—¶ä»»åŠ¡æµ‹è¯•

### 6.3 æµ‹è¯•æ•°æ®

- å‡†å¤‡æ¨¡æ‹ŸHTMLæ–‡ä»¶ç”¨äºè§£ææµ‹è¯•
- å‡†å¤‡é…ç½®æ–‡ä»¶æµ‹è¯•ç”¨ä¾‹

## 7. æ³¨æ„äº‹é¡¹

### 7.1 åçˆ¬ç­–ç•¥åº”å¯¹

- è®¾ç½®åˆç†çš„è¯·æ±‚é—´éš”ï¼ˆ2-5ç§’ï¼‰
- éšæœºåŒ–User-Agent
- æ”¯æŒä»£ç†IPåˆ‡æ¢ï¼ˆé¢„ç•™æ¥å£ï¼‰
- å¤„ç†éªŒè¯ç é¡µé¢ï¼ˆè®°å½•æ—¥å¿—ï¼Œè·³è¿‡ï¼‰

### 7.2 æ•°æ®è´¨é‡ä¿è¯

- ä¸¥æ ¼çš„æ•°æ®æ¸…æ´—å’Œæ ¡éªŒ
- å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•
- æ”¯æŒæ–­ç‚¹ç»­é‡‡

### 7.3 ç»´æŠ¤å»ºè®®

- å®šæœŸæ£€æŸ¥ç½‘ç«™ç»“æ„å˜åŒ–
- åŠæ—¶æ›´æ–°è§£æè§„åˆ™
- å®šæœŸæ¸…ç†æ—§æŠ¥å‘Šå’Œæ—¥å¿—
